# -*- coding: utf-8 -*-
"""0520281B-exp5-4-jaen-寺面杏優.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lTn0Iu_k6CiBV2izOSdtIj576VL7iOT-

# 事前にやること
1. ランタイムのタイプを "GPU" に変更
2. 設定ファイル "rnn.yaml" および "san.yaml" をアップロード
"""

from google.colab import drive
drive.mount('/content/drive')

# ライブラリのインストール

! pip install janome
! pip install OpenNMT-py

# 前処理（日本語の単語分割）

from janome.tokenizer import Tokenizer
tokenizer = Tokenizer()

# train
fout = open("ja.train.txt", "w")
fin = open("/content/drive/MyDrive/translation/ja.comp.train.txt", "r")
for line in fin:
    fout.write(" ".join([token.surface for token in tokenizer.tokenize(line.strip())]) + "\n")
fin.close()
fout.close()
! cp "/content/drive/MyDrive/translation/en.train.txt" "en.train.txt"

# valid
fout = open("ja.valid.txt", "w")
fin = open("/content/drive/MyDrive/translation/ja.comp.valid.txt", "r")
for line in fin:
    fout.write(" ".join([token.surface for token in tokenizer.tokenize(line.strip())]) + "\n")
fin.close()
fout.close()
! cp "/content/drive/MyDrive/translation/en.valid.txt" "en.valid.txt"

# test
fout = open("ja.test.txt", "w")
fin = open("/content/drive/MyDrive/translation/ja.comp.test.txt", "r")
for line in fin:
    fout.write(" ".join([token.surface for token in tokenizer.tokenize(line.strip())]) + "\n")
fin.close()
fout.close()
! cp "/content/drive/MyDrive/translation/en.test.txt" "en.test.txt"

from janome.tokenizer import Tokenizer
tokenizer = Tokenizer()

# ja.comp.eval.txt
fout = open("ja.comp.eval.txt", "w")
fin = open("/content/drive/MyDrive/translation/ja.comp.eval.txt", "r")
for line in fin:
    fout.write(" ".join([token.surface for token in tokenizer.tokenize(line.strip())]) + "\n")
fin.close()
fout.close()

# データセットの準備

! onmt_build_vocab -config "/content/drive/MyDrive/translation/kikai-model.yaml" -n_sample 50000

# 訓練

! onmt_train -config "/content/drive/MyDrive/translation/kikai-model.yaml"

# xent : クロスエントロピー

# 翻訳

! onmt_translate -model "/content/drive/MyDrive/translation/kikai/transformer_step_5000.pt" "/content/drive/MyDrive/translation/kikai/transformer_step_6500.pt" "/content/drive/MyDrive/translation/kikai/○transformer_step_7500.pt" -src "ja.comp.eval.txt" -output "pred.rnn.en.ans.txt" -gpu "0" -verbose
# どのモデルでやるか　どのテキストを入力するか　どのファイルに出力するのか　colabのGPUは1つなので"0"

# 機械翻訳
! pip install mosestokenizer

from mosestokenizer import MosesTokenizer
tokenizer = MosesTokenizer("en", "no-escape")

fname = "pred.rnn.en.ans.txt"

fout = open(fname.replace(".txt", ".tok.txt"), "w")
fin = open(fname, "r")
for line in fin:
    fout.write(" ".join([word for word in tokenizer(line.strip().lower())]) + "\n")
fin.close()
fout.close()

"""7000と7500 : 36.11 → 38.49  
6000 : 34.38  
6500 : 35.17  
7000 : 35.11  
7500 : 35.64  
700075006500 : → 38.69  
700075006000 : → 38.88    
700075005500 : →38.91  
700075005000 : →38.82  
7000750065006000 : → 38.82   
7000750065005500 : → 38.71  
7000750060005500 : → 38.63   
70007500650060005500 : → 38.70 

"""