# -*- coding: utf-8 -*-
"""0520281B-exp4-4-寺面杏優（課題1）.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1swacW6SrEKrHGSveiNe7iODr0trypf6e
"""

# ====================
# ライブラリのインストール
# ====================

! pip install pytorch_lightning

# ====================
# データセットをダウンロード
# ====================

import torch
import torchvision

train = torchvision.datasets.CIFAR10(root="./", train=True, download=True, transform=torchvision.transforms.ToTensor())
test = torchvision.datasets.CIFAR10(root="./", train=False, download=True, transform=torchvision.transforms.ToTensor())

# ====================
# データの内容を確認
# ====================

import numpy as np
import matplotlib.pyplot as plt

print("学習用：", train.data.shape)  # 5万枚の画像があり、各画像は32pixel×32pixel×3色
print("評価用：", test.data.shape)  # # 1万枚の画像があり、各画像は32pixel×32pixel×3色

# ラベル
classes = train.classes
print(classes)

for i in range(5):
    print(train[i])  # # 学習用データの内容（32次元×32次元×3色分の特徴量とラベルの組）を表示
    plt.imshow(np.transpose(train[i][0].numpy(), (1, 2, 0)))  # カラー画像をnumpy形式に変換して表示
    plt.text(2, 30, "label: "+str(classes[train[i][1]]), color="white")  # ラベルを表示
    plt.show()

# ====================
# 画像とラベルをDataLoaderに格納
# ====================

from torch.utils.data import random_split
from torch.utils.data import DataLoader

batch_size = 100

# 6万件のうち1万件を検証用に分割
train, val = random_split(train, [42500, 7500])

# DataLoaderに格納
train_loader = DataLoader(train, batch_size, shuffle=True)
val_loader = DataLoader(val, batch_size, shuffle=False)
test_loader = DataLoader(test, batch_size, shuffle=False)

print("学習用：", len(train))
print("検証用：", len(val))
print("評価用：", len(test))

# ====================
# ネットワークの定義（MLP）
# ====================

from torch import nn
import torch.nn.functional as F
import pytorch_lightning as pl


class Net(pl.LightningModule):

    # モデルの構造
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(32*32*3, 10000)  # 784次元の入力層から10次元の中間層への全結合
        self.fc2 = nn.Linear(10000, 5000)  # 10次元の中間層から10次元の出力層への全結合
        self.fc3 = nn.Linear(5000, 1000)  # 10次元の中間層から10次元の出力層への全結合
        self.fc4 = nn.Linear(1000, 10)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc5 = nn.Linear(3000, 2000)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc6 = nn.Linear(2000, 1500)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc7 = nn.Linear(1500, 1000)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc8 = nn.Linear(1000, 800)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc9 = nn.Linear(800, 600)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc10 = nn.Linear(600, 450)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc11 = nn.Linear(450, 300)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc12 = nn.Linear(300, 150)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc13 = nn.Linear(150, 100)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc14 = nn.Linear(100, 70)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc15 = nn.Linear(70, 50)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc16 = nn.Linear(50, 30)  # 10次元の中間層から10次元の出力層への全結合
        # self.fc17 = nn.Linear(30, 10)  # 10次元の中間層から10次元の出力層への全結合


    # 順伝播
    def forward(self, x):
        h = F.relu(self.fc1(x))  # xを線形変換（fc1）し、非線形変換（relu）し、中間表現hを得る
        y1 = self.fc2(h)  # 中間表現hを線形変換（fc2）し、出力y1を得る
        y2 = self.fc3(y1)  # 中間表現hを線形変換（fc3）し、出力y2を得る
        y = self.fc4(y2)  # 中間表現hを線形変換（fc4）し、出力y3を得る
        # y4 = self.fc5(y3)  # 中間表現hを線形変換（fc5）し、出力y4を得る
        # y5 = self.fc6(y4)  # 中間表現hを線形変換（fc2）し、出力y1を得る
        # y6 = self.fc7(y5)  # 中間表現hを線形変換（fc3）し、出力y2を得る
        # y7 = self.fc8(y6)  # 中間表現hを線形変換（fc4）し、出力y3を得る
        # y8 = self.fc9(y7)  # 中間表現hを線形変換（fc5）し、出力y4を得る
        # y9 = self.fc10(y8)  # 中間表現hを線形変換（fc2）し、出力y1を得る
        # y10 = self.fc11(y9)  # 中間表現hを線形変換（fc3）し、出力y2を得る
        # y11 = self.fc12(y10)  # 中間表現hを線形変換（fc4）し、出力y3を得る
        # y12 = self.fc13(y11)  # 中間表現hを線形変換（fc5）し、出力y4を得る
        # y13 = self.fc14(y12)  # 中間表現hを線形変換（fc2）し、出力y1を得る
        # y14 = self.fc15(y13)  # 中間表現hを線形変換（fc3）し、出力y2を得る
        # y15 = self.fc16(y14)  # 中間表現hを線形変換（fc4）し、出力y3を得る
        # y = self.fc17(y15)  # 中間表現hを線形変換（fc5）し、出力y4を得る
        return y

    # 損失関数
    def criterion(self, y, t):
        return F.cross_entropy(y, t)

    # 最適化手法
    def configure_optimizers(self):
        return torch.optim.SGD(self.parameters(), lr=0.01)

    # ==========
    # 学習用データに対する処理
    # ==========

    def training_step(self, batch, batch_idx):
        x, t = batch  # 黄色の部分の処理
        x = x.view(-1, 32*32*3)  # 2次元の画像データを1次元のベクトルに並び替え
        y = self.forward(x)  # 赤色の部分の処理
        loss = self.criterion(y, t)  # 緑色の部分の処理
        return {"loss": loss}

    # ==========
    # 検証用データに対する処理
    # ==========

    # ステップごとの処理
    def validation_step(self, batch, batch_idx):
        x, t = batch  # 黄色の部分の処理
        x = x.view(-1, 32*32*3)  # 2次元の画像データを1次元のベクトルに並び替え
        y = self.forward(x)  # 赤色の部分の処理
        loss = self.criterion(y, t)  # 緑色の部分の処理
        return {"val_loss": loss}
    
    # エポックごとの処理
    def validation_epoch_end(self, outputs):
        avg_loss = torch.stack([o["val_loss"] for o in outputs]).mean()  # outpus: 各ステップの返り値が保存されている
        print("Epoch: %02d  val_loss: %.3f" % (self.current_epoch + 1, avg_loss))
    
    # ==========
    # 評価用データに対する処理
    # ==========

    def predict_step(self, batch, batch_idx):
        x, t = batch  # 黄色の部分の処理
        x = x.view(-1, 32*32*3)  # 2次元の画像データを1次元のベクトルに並び替え
        y = self.forward(x)  # 赤色の部分の処理
        return y

# ネットワークのインスタンスを作成
net = Net()
net

# ====================
# 学習
# ====================

trainer = pl.Trainer(max_epochs=40, accelerator="auto")
trainer.fit(net, train_loader, val_loader)

# ====================
# 評価
# ====================

from sklearn.metrics import classification_report

preds = trainer.predict(net, test_loader)  # ミニバッチごとに、各ラベルに対する予測値が出力される
preds = torch.concat(preds).argmax(axis=1)  # ミニバッチへの分割を元に戻し、事例ごとに最高の予測値を持つラベルを選ぶ

golds = torch.concat([t for x, t in test_loader])
print(classification_report(golds, preds, digits=3))

# ====================
# 実例の確認
# ====================

for i in range(10):
    plt.imshow(test[i][0][0], cmap="rainbow_r")
    plt.text(2, 2, "Gold: %d  Pred: %d" % (test[i][1], preds[i]), color="white")
    plt.show()

# ====================
# 実例の確認
# ====================

for i in range(10):
    plt.imshow(np.transpose(test[i][0].numpy(), (1, 2, 0)))
    plt.text(2, 2, "Gold: %d  Pred: %d" % (test[i][1], preds[i]), color="white")
    plt.show()