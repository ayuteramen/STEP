# -*- coding: utf-8 -*-
"""0520281b-exp4-4-寺面杏優(課題2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RkwitXfN6vz6o29nCma8s5ljCExTcX_B
"""

# ====================
# ライブラリのインストール
# ====================

! pip install pytorch_lightning

# ====================
# データセットをダウンロード
# ====================

import torch
import torchvision

train = torchvision.datasets.CIFAR10(root="./", train=True, download=True, transform=torchvision.transforms.ToTensor())
test = torchvision.datasets.CIFAR10(root="./", train=False, download=True, transform=torchvision.transforms.ToTensor())

# ====================
# データの内容を確認
# ====================

import numpy as np
import matplotlib.pyplot as plt

print("学習用：", train.data.shape)  # 5万枚の画像があり、各画像は32pixel×32pixel×3色
print("評価用：", test.data.shape)  # # 1万枚の画像があり、各画像は32pixel×32pixel×3色

# ラベル
classes = train.classes
print(classes)

for i in range(5):
    print(train[i])  # # 学習用データの内容（32次元×32次元×3色分の特徴量とラベルの組）を表示
    plt.imshow(np.transpose(train[i][0].numpy(), (1, 2, 0)))  # カラー画像をnumpy形式に変換して表示
    plt.text(2, 30, "label: "+str(classes[train[i][1]]), color="white")  # ラベルを表示
    plt.show()

# ====================
# 画像とラベルをDataLoaderに格納
# ====================

from torch.utils.data import random_split
from torch.utils.data import DataLoader

batch_size = 100

# 6万件のうち1万件を検証用に分割
train, val = random_split(train, [47500, 2500])

# DataLoaderに格納
train_loader = DataLoader(train, batch_size, shuffle=True)
val_loader = DataLoader(val, batch_size, shuffle=False)
test_loader = DataLoader(test, batch_size, shuffle=False)

print("学習用：", len(train))
print("検証用：", len(val))
print("評価用：", len(test))

# ====================
# ネットワークの定義（CNN）
# ====================

from torch import nn
import torch.nn.functional as F
import pytorch_lightning as pl


class Net(pl.LightningModule):

    # モデルの構造
    def __init__(self):
        super().__init__()
        # 畳み込み層
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=512, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=512, out_channels=2048, kernel_size=3)
        self.conv3 = nn.Conv2d(in_channels=2048, out_channels=8192, kernel_size=3)
        # プーリング層
        self.pool = nn.MaxPool2d(kernel_size=2)
        # 全結合層
        self.fc1 = nn.Linear(8192*2*2, 1000)
        self.fc2 = nn.Linear(1000, 10)

    # 順伝播
    def forward(self, x):
        h = self.pool(F.relu(self.conv1(x)))  # (1*28*28) -> (32*24*24) -> (32*12*12)
        h = self.pool(F.relu(self.conv2(h)))  # (32*12*12) -> (64*10*10) -> (64*5*5)
        h = self.pool(F.relu(self.conv3(h)))
        h = torch.flatten(h, 1)  # (64*5*5) -> 1,600次元のベクトル
        h = F.relu(self.fc1(h))  # 1,600 -> 100
        y = self.fc2(h)  # 100 -> 10
        return y

    # 損失関数
    def criterion(self, y, t):
        return F.cross_entropy(y, t)

    # 最適化手法
    def configure_optimizers(self):
        return torch.optim.SGD(self.parameters(), lr=0.01)

    # ==========
    # 学習用データに対する処理
    # ==========

    def training_step(self, batch, batch_idx):
        x, t = batch  # 黄色の部分の処理
        y = self.forward(x)  # 赤色の部分の処理
        loss = self.criterion(y, t)  # 緑色の部分の処理
        return {"loss": loss}

    # ==========
    # 検証用データに対する処理
    # ==========

    # ステップごとの処理
    def validation_step(self, batch, batch_idx):
        x, t = batch  # 黄色の部分の処理
        y = self.forward(x)  # 赤色の部分の処理
        loss = self.criterion(y, t)  # 緑色の部分の処理
        return {"val_loss": loss}
    
    # エポックごとの処理
    def validation_epoch_end(self, outputs):
        avg_loss = torch.stack([o["val_loss"] for o in outputs]).mean()  # outpus: 各ステップの返り値が保存されている
        print("Epoch: %02d  val_loss: %.3f" % (self.current_epoch + 1, avg_loss))
    
    # ==========
    # 評価用データに対する処理
    # ==========

    def predict_step(self, batch, batch_idx):
        x, t = batch  # 黄色の部分の処理
        y = self.forward(x)  # 赤色の部分の処理
        return y

# ネットワークのインスタンスを作成
net = Net()
net

# ====================
# 学習
# ====================

trainer = pl.Trainer(max_epochs=50, accelerator="auto")
trainer.fit(net, train_loader, val_loader)

# ====================
# 評価
# ====================

from sklearn.metrics import classification_report

preds = trainer.predict(net, test_loader)  # ミニバッチごとに、各ラベルに対する予測値が出力される
preds = torch.concat(preds).argmax(axis=1)  # ミニバッチへの分割を元に戻し、事例ごとに最高の予測値を持つラベルを選ぶ

golds = torch.concat([t for x, t in test_loader])
print(classification_report(golds, preds, digits=3))

# ====================
# 実例の確認
# ====================

for i in range(10):
    plt.imshow(test[i][0][0], cmap="gray")
    plt.text(2, 2, "Gold: %d  Pred: %d" % (test[i][1], preds[i]), color="white")
    plt.show()



